\chapter{Matching} \label{chapter:matching}
In order to analyze the lead-lag relationship of corporate bonds and stocks, we need a large, survivorship bias free database with both stock and bond returns for any given point in time. So far, we only have two separate databases -- one with historical corporate bonds data, and one with historical equity data. Therefore, the two databases have to be joined into one, based on the company that issued both. The task is not as trivial as it might seem, since there is no unique company identifier available in both databases. In the following, the available matching options will be discussed, and the most suitable approach chosen. 

\section{Available Options}
To begin with, the following extracted bond and equity parameters were considered for the matching: 
\begin{itemize}
	\item SEDOL code
	\item WKN code
	\item CUSIP-9 code
	\item ISIN code
	\item Worldscope identifier
	\item Company name
\end{itemize}

\subsection{SEDOL} %TODO ref https://www.investopedia.com/terms/s/sedol.asp
The SEDOL is a unique 7-character identification code which stands for 'Stock Exchange Daily Official List'. It is issued for securities registered in the United Kingdom and Ireland by the London Stock Exchange. Despite being used to uniquely identify securities, it does not, in general, contain a unique issuing company identifier, because the codes are simply issued sequentially. For example, two bonds, which were both issued by Apple Inc., can have the SEDOL codes \textit{BF43J24} and \textit{BK9WPP6}, respectively. The only similarity between the two is that these were issued only two years apart, and thus have the \textit{B} at the beginning in common. Besides, the identifier is not available in our stocks database, and only exists for securities of companies listed on the LSE. 

\subsection{WKN} %TODO ref downloaded pdf
The WKN is a German 6-digit alphanumeric security identification code and stands for 'Wertpapierkennnummer'. Since 2004, it is possible for companies to obtain a WKN with a unique company identifier included. A WKN includes a company identifier if it starts with at least two characters before proceeding with digits. However, not all companies make use of this opportunity when ordering a WKN for their securities. Taking into account that there are also multiple exceptions from the rule base of WKN identifiers, it is hard to use these as unique company identifiers. This is especially the case because WKN are generally only available for German securities. Also, the parameter is not available in our existing equities database. 

\subsection{CUSIP-9} %TODO ref https://www.investopedia.com/terms/c/cusipnumber.asp
The CUSIP number is a unique identification number assigned to all equities and bonds that are registered in the United States and Canada. The CUSIP consists of 9 alphanumeric characters, of which the first 6 comprise the unique issuing company identifier. The code is often used in one of its shorter forms, i.e. as CUSIP-8 and CUSIP-6. However, in our case, only the CUSIP-6 variant is of interest. It can be derived from CUSIP-9 by simply dropping the last three characters. The CUSIP-9 code is directly available in our equities database. In the bonds database, it can only be found directly for some of the securities in the so-called \textit{local code} variable (LOC), which can be found in Datastream. Unfortunately, the CUSIP values entered in this variable are not very reliable. A workaround can be achieved by using the security ISIN, as will be explained in \ref{section:cusip-matching}. 

\subsection{ISIN} %TODO ref internet
The ISIN stands for 'International Securities Identification Number' and is an international standard way to uniquely identify securities. The ISIN by itself is not a unique company identifier. However, it sometimes contains a company identifier as part of it. In particular, for U.S. and Canadian securities, the ISIN usually contains the Cusip-9 code, which, in its turn, contains a 6-digit unique company identifier. For U.K. and Irish securities, the ISIN usually contains the SEDOL code. And for German securities, the ISIN contains the WKN. Therefore, while the ISIN itself cannot be directly used for the matching, it can nevertheless be used to obtain missing matching code values by extracting them from the ISIN. 

\subsection{Worldscope identifier} %TODO cite Datastream database explanation, mb include in appendix
The Worldscope Identifier is a 9-digit code issued by Worldscope, a Thomson Reuters' fundamentals product. It is used to uniquely identify both issuing companies and securities. For U.S. companies, the Worldscope Identifier is identical with the CUSIP-9 code. For non-U.S. companies, a derived identifier is used, based on the country where the issuing company is domiciled, and also includes a unique company code. A more detailed explanation of the mechanics can be found in the Datastream database or the appendix to this work. %TODO ref appendix screenshots
Unfortunately, the Worldscope Identifier is only available in the equities database, and not for bonds. Therefore, it cannot be used for the matching. 

\subsection{Company name}
As the 'method of last resort', the company name itself can be used to join the bond and equity databases. The problem with company names as identifiers is though that these are not necessarily unique on the one hand, and also tend to have heterogeneous spelling -- i.e. one and the same company can be spelled in multiple different ways across the database. To provide an example, the company names \textit{THE WILLIAMS COMPANIES INCO} and \textit{WILLIAMS PARTNERS L.P.} refer to the same company, but are written differently, which makes the join between the two databases ambiguous. Nevertheless, the approach can be a good starting point when other options are not available, and will be introduced in greater detail in the next section. 

\section{Fuzzy String Matching} \label{section:fuzzy-string-matching}
Having considered the different options to perform the matching, it becomes apparent that the only unique identifier which can be reliably used for the task is the CUSIP-9 code. Additionally, the company name can be used to produce a solid baseline to start with. In this section, a matching approach called Fuzzy String Matching will be introduced as a means to join the datasets via company name. In the next section, a matching approach based on the CUSIP code will be explained. 

The term Fuzzy String Matching -- also called Approximate String Matching -- refers to use cases when there are two or more strings which have the same meaning, but are spelled somewhat differently. There exist multiple approaches to measure the extent of 'difference' between strings. The formula which is most commonly used is the so-called Levenshtein distance. It measures the minimum number of single-character edits required to change one given sequence into the other. An \textit{edit}, in its turn, is defined as one of the three operations performed on a string: 
\begin{itemize}
	\item insertion
	\item deletion
	\item substitution
\end{itemize}
Depending on the implementation, a substitution of a character can count as either one or two edits. This is because a substitution technically consists of both an insertion and a deletion. For simplicity reasons it can be assumed to count as one edit just like the other two operations. To give an example, consider a company that is called \textit{Apple Inc.} in one dataset and \textit{Apple Incorp.} in the other. The Levenshtein distance between the two company names would be 3, because exactly 3 insertions need to be performed in order to produce \textit{Apple Incorp.} from \textit{Apple Inc.} These insertions are the 3 characters \textit{o}, \textit{r} and \textit{p}. Alternatively, we can also start the other way around, from the company name \textit{Apple Incorp.} In this case, we would need 3 deletions to produce \textit{Apple Inc.} In particular, we would have to delete the 3 characters \textit{o}, \textit{r} and \textit{p}. 

While there exists a concrete formula which defines the Levenshtein distance, it is not very relevant in this context, since we will not be implementing the Levenshtein distance ourselves. 
%TODO cite both levenshtein distance and its formula
Instead, we will make use of dedicated Python packages, which compute the Levenshtein distance between two strings behind the scenes in order to produce a similarity score. In this work, we consider the two packages \textit{fuzzywuzzy}\footnote{https://pypi.org/project/fuzzywuzzy} and \textit{rapidfuzz}\footnote{https://pypi.org/project/rapidfuzz} for the task. In reality, these packages do slightly more than just computing the edit distance, depending on the particular function called. A detailed description of these packages' capabilities can be found in their respective documentation. 

The concept will be used in our case to select for each company name from the bonds database the one from the equities database which has the smallest Levenshtein distance to it. This way, matching company names from the two datasets will be connected to each other to produce a join. 

\subsection{Fuzzy-Wuzzy}
\textit{Fuzzywuzzy} is the most commonly used package for fuzzy string matching in the Python community. Therefore, my first approach to perform the matching was with the fuzzywuzzy package. It requires additionally the package \textit{python-Levenshtein} to be installed, so it can use its faster C implementation of the Levenshtein distance. The rest of the \textit{fuzzywuzzy} package is programmed in Python. 

To start with the implementation, the static bond and equity data needs to be read into \textit{pandas}\footnote{https://pandas.pydata.org} dataframes to perform further operations on it. For this purpose, it is advisable to export the static data from Stata to the CSV\footnote{CSV means comma-separated-values and is a frequently used data storage format. In the first row of a CSV file there are usually column headers, all separated by commas. In all further rows the single column values are stored, also separated by commas. The format is frequently used in data science applications due it being lightweight and information-dense. } format, and then to import it in Python from CSV files. I explicitly discourage exporting data from Excel to CSV, because Excel has its own understanding of the CSV format, which might not be compatible with \textit{pandas}. 

After the data has been loaded into dataframes, one for bond company names, and one for stock company names, it can be fed into one of the predefined \textit{fuzzywuzzy} functions. To start simple, two company names can be compared to each other with the built-in function ratio(), which computes the standard Levenshtein distance similarity ratio between the two sequences. Note that this function also takes into account whether the characters are capitalized or not. Thus, \textit{Apple Inc. }and \textit{apple Inc.} would produce a similarity ratio lower than 100\% due to the difference in the capitalization of the first letter. This is a not very desired behavior for our use case, because we do not care much whether a company's name is written in upper or lower case letters. 

\subsection{Rapidfuzz}


\section{CUSIP Matching} \label{section:cusip-matching}

\section{Evaluation} \label{section:matching-evaluation}



